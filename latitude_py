#ADD EMPTY COLUMN
df["column_name"] = np.nan

#CHECK IF DATAFRAME IS EMPTY
df.empty (this is a boolean, TRUE/FALSE)


#COMBINE MULTIPLE COLUMNS INTO ONE
df['col3'] = df[['col1', 'col2', colx]].agg(' '.join, axis=1)


#CONVERT TO LOWER CASE
df['column'] = df['column'].str.lower()


#COUNT ELEMENTS IN COLUMN
df['column'].value_counts()


#COUNT ELEMENTS IN COLUMNS W/ CONDITION
len(df.groupby('col_1').apply(lambda g: pd.Series(g['col_2'].unique())))


#CREATE DICTIONARY WITH LOOP
keys = list(df.col.value_counts().keys())
values = []
for key in keys:
    dft = df[df.col == key].copy()
    value = df.col.mean()
    values.append(value)
dicts = {}    
for i in range(len(keys)):
    dicts[keys[i]] = values[i]


#DATE/TIME
today = datetime.today().strftime('%Y-%m-%d')


#DOWNLOAD REQUESTS AS FILES
t = requests.get(url)
open("file_name.csv", "wb").write(t.content)
t = pd.read_csv("file_name.csv", sep=';')


#DELETE COLUMN
del second["column_name"]


#DISPLAY ATTRIBUTES OF OBJECT
vars(object)


#DROP COLUMNS
df.drop(['B', 'C'], axis=1)


#DROP ROWS W/ CONDITIONS
to_remove = df[df['column_name'] == 'element' ].index
df.drop(to_remove , inplace=True)


#EXPAND ONE COLUMN INTO MANY
df[['new_col1','new_col2']]=df.col.str.split('-',expand=True)


#EXPAND COLUMN OF DICTIONARIES
df = pd.concat([df.drop(['dict_col'], axis=1), df['dict_col'].apply(pd.Series)], axis=1)


#GET DICTIONARY KEYS (key_2 is for nested dictionaries)
variable_name = dict.get('key_1', {}).get('key_2')  


#GET PERCENTAGES
df['col'].value_counts(normalize=True)


#JOIN LIST ELEMENTS INTO A SINGLE STRING
x = ' '.join(str(e) for e in list)

#MERGE DATAFRAMES W/ CONCAT
df = pd.concat([df_1, df_2], ignore_index=True) 


#MERGE DATAFRAMES W/ MERGE
new_df = df_1.merge(df_2, how='left', left_on="column_1", right_on="column_2")


# MERGE DICTIONARIES
dictionary = dict1 | dict2



#READ FILES
df = pd.read_excel(f"results/file_name.xlsx")
df = pd.read_csv(f"results/file_name.csv", sep=",", encoding='latin1')


#READ MULTIPLE FILES
empty_list = []
for j in range(1,16):
    file = "../../results/norvodisk/dirty_data/raw_{}.csv".format(j)
    empty_list.append(file)

empty_df = pd.DataFrame()
for name in empty_list:
    file = pd.read_csv(name, encoding='utf-8')
    empty_df = pd.concat([empty_df, file])
empty_df = empty_df.reset_index(drop=True)


#REMOVE LAST ROW
df = df.iloc[: , :-1]


#RENAME COLUMNS
df = df.rename(columns={"original_name": "new_name"})


#REPLACE W/ DICTIONARY
dictionary = {'é|è':'e',
             'ï':'i',
              'ô':'o'}

df['col'] = df["col"].replace(dictionary, regex=True)



#REPLACE W/ WHERE (AFFECTS ALL ROWS)
df["new_column"] = np.where(df["column_1"]==df["column_2"], "if_true", "if_false")


#REPLACE W/ FOR (AFFECTS SPECIFIC ROWS)
for index in df.index:
    if df.loc[index,'column_name_1']==0:
        df.loc[index,'column_name_1'] = np.nan
        df.loc[index,'column_name_2'] = "str"
        df.loc[index,'column_name_1'] = int
        
        
#REPLACE AS LOOP (runs every element of the list)
list = [element1, element2]
str = "any string with {}"

for element in list:
    x = str.format(list)


#REPLACE EXACT STR/INT
df["column_name"] = df["column_name"].replace(element_to_replace, element_to_add)


# REMOVE ALL nan IN A DATAFRAME
df[col.isna().any(axis=1)]


#REMOVE LEADING SPACE IN STRING COLUMN
for index in df.index:
    df.loc[index, 'col'] = df.loc[index, 'col'].lstrip(' ')


#REMOVE UNNAMED COLUMNS
df = df.loc[:, ~df.columns.str.contains('^Unnamed')]


#REMOVE ITEM FROM LIST
list.remove(item)


#SELECT ROWS BY INDEX
df = df.iloc[200:400]

#SELECT ROWS w/ CONDITIONS
filterinfDataframe = df[(df['column'] > 30) & (df['column'] < 33) ]


#SLEEP
time.sleep(1)


#SORT ROWS
df.sort_values(by='col1', ascending=False)


# TRANSFORM DATAFRAME TO DICTIONARY
dictionary = dict(zip(df.col_1, df.col_2))


#TRANSFORM COLUMN TO DATETIME
df['col'] = pd.to_datetime(df['col'])


#UNZIP FILES - Extract all the contents of zip file in current directory
from zipfile import ZipFile
t = requests.get(url)
open("file_name.zip", "wb").write(t.content)
with ZipFile('file_name.zip', 'r') as zipObj:
   zipObj.extractall()



COMPLEX FUNCTIONS:

def separate_mapped(df):
    mapped_df = df[df['concept_id']!=0].copy()
    mapped_list = mapped_df['label'].tolist()
    remaining_df = df[~df['label'].isin(mapped_list)]
    remaining_df = remaining_df.drop(['col_1', 'col_2'], axis=1)
    mapped_df = mapped_df.drop_duplicates(subset=['col_1', 'col_2'], keep="last")
    return mapped_df, remaining_df

def find_duplicates(df):
    no_dups_df = df.drop_duplicates(subset=["source_value", 'source_concept_code', 'country'], keep=False)
    no_dups_list = no_dups_df['source_value'].tolist()
    duplicate_list = df[~df['source_value'].isin(no_dups_list)]
    duplicate_list = duplicate_list['source_value'].to_list()
    df['multiple_map'] = df['source_value'].isin(duplicate_list)
    for index in df.index:
        if df.loc[index,'multiple_map']==True:
            df.loc[index,'multiple_map'] = 1
            df.loc[index,'is_reviewed'] = 1
        else:
            df.loc[index, 'multiple_map'] = 0
            df.loc[index,'is_reviewed'] = 0        
    return df

def final_format(df):
  df['concept_id'] = df['concept_id'].fillna(0)  
  integers = ['source_concept_code', 'concept_id']
  strings = ['domain_id', 'concept_name']
  displays = ['map_type', 'vocabulary_id', 'domain_id', 'standard_concept', 'multiple_map', 'mapping_date']
  for element in integers:
      df[element] = df[element].astype(int)
  for element in strings:
      df[element] = df[element].str.lower()
  for element in displays:
      print(element.upper(), ':')
      print(df[element].value_counts(), sep=';', end='\n')
      print(' ')
  df = df.sort_values(by=['country','source_concept_code'])
  return df
